{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prof-eduardo-nunes/unicamp-mineracao_dados/blob/main/Aula_YOLOv8_Dataset_Tomates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FLKz-jSMN00"
      },
      "source": [
        "# Aula Prática: Detecção de Tomates com YOLOv8\n",
        "## Usando Dataset Personalizado (895 Imagens)\n",
        "\n",
        "**Objetivo:** Desenvolver um sistema completo de detecção de tomates em lavoura, desde a preparação do dataset até o treinamento e inferência.\n",
        "\n",
        "**Dataset:** 895 imagens de tomates em estufa fornecidas pelo usuário\n",
        "\n",
        "**Aplicações Práticas:**\n",
        "- Colheita automatizada\n",
        "- Monitoramento de maturação\n",
        "- Estimativa de produção\n",
        "- Controle de qualidade\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fR6A9lYMN01"
      },
      "source": [
        "## Parte 1: Configuração do Ambiente\n",
        "\n",
        "Primeiro, vamos instalar todas as bibliotecas necessárias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kMmZYvRMN02",
        "outputId": "ee76b045-5fbc-48f6-ff3a-f24175590dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Bibliotecas instaladas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Instalação das bibliotecas\n",
        "!pip install \"ultralytics<=8.3.40\" -q\n",
        "!pip install roboflow -q\n",
        "\n",
        "print(\"✓ Bibliotecas instaladas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tToWyD7-MN02",
        "outputId": "0388d554-218b-471d-b02f-cff800d4c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "✓ Bibliotecas importadas!\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print(\"✓ Bibliotecas importadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CapXnVdMN03"
      },
      "source": [
        "## Parte 2: Upload e Preparação do Dataset\n",
        "\n",
        "### 2.1. Upload do Dataset\n",
        "\n",
        "Faça upload do arquivo `fotostomate.zip` quando solicitado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9XOtsMy4MN03",
        "outputId": "4bc595be-acf3-46fa-bc66-6efd862c2136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, faça upload do arquivo fotostomate.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d2fe877-f898-4d37-8e77-68cab0183824\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d2fe877-f898-4d37-8e77-68cab0183824\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Upload do arquivo ZIP\n",
        "print(\"Por favor, faça upload do arquivo fotostomate.zip\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Descompactar\n",
        "!unzip -q fotostomate.zip -d dataset_original\n",
        "print(\"✓ Dataset descompactado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YSLT0SwMN03"
      },
      "source": [
        "### 2.2. Exploração Inicial do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5dadsYAMN03"
      },
      "outputs": [],
      "source": [
        "# Verificar estrutura do dataset\n",
        "!ls -la dataset_original/\n",
        "\n",
        "# Contar imagens\n",
        "image_dir = \"dataset_original/images\"\n",
        "images = list(Path(image_dir).glob(\"*.png\")) + list(Path(image_dir).glob(\"*.jpg\"))\n",
        "print(f\"\\nTotal de imagens: {len(images)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_g54sNMN03"
      },
      "source": [
        "### 2.3. Visualizar Amostras do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-f2Y2ppMN03"
      },
      "outputs": [],
      "source": [
        "# Visualizar 6 imagens aleatórias\n",
        "sample_images = random.sample(images, 6)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, img_path in enumerate(sample_images):\n",
        "    img = Image.open(img_path)\n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"{img_path.name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n📊 Observações:\")\n",
        "print(\"- Tomates em diferentes estágios de maturação\")\n",
        "print(\"- Ambiente de estufa/cultivo protegido\")\n",
        "print(\"- Variação de iluminação e ângulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvDcAjmyMN04"
      },
      "source": [
        "## Parte 3: Divisão do Dataset\n",
        "\n",
        "Vamos dividir o dataset em conjuntos de treino (70%), validação (20%) e teste (10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djGYL9cDMN04"
      },
      "outputs": [],
      "source": [
        "def dividir_dataset(source_dir, dest_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Divide o dataset em train/val/test\n",
        "    \"\"\"\n",
        "    # Obter lista de imagens\n",
        "    source_path = Path(source_dir)\n",
        "    images = list(source_path.glob(\"*.png\")) + list(source_path.glob(\"*.jpg\"))\n",
        "\n",
        "    # Embaralhar\n",
        "    random.seed(42)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    # Calcular divisões\n",
        "    total = len(images)\n",
        "    train_end = int(total * train_ratio)\n",
        "    val_end = train_end + int(total * val_ratio)\n",
        "\n",
        "    train_images = images[:train_end]\n",
        "    val_images = images[train_end:val_end]\n",
        "    test_images = images[val_end:]\n",
        "\n",
        "    # Criar estrutura de diretórios\n",
        "    dest_path = Path(dest_dir)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        (dest_path / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
        "        (dest_path / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copiar imagens\n",
        "    def copiar(img_list, split):\n",
        "        for img in img_list:\n",
        "            dest = dest_path / 'images' / split / img.name\n",
        "            shutil.copy2(img, dest)\n",
        "\n",
        "    copiar(train_images, 'train')\n",
        "    copiar(val_images, 'val')\n",
        "    copiar(test_images, 'test')\n",
        "\n",
        "    return {\n",
        "        'train': len(train_images),\n",
        "        'val': len(val_images),\n",
        "        'test': len(test_images)\n",
        "    }\n",
        "\n",
        "# Executar divisão\n",
        "stats = dividir_dataset('dataset_original/images', 'dataset_yolo')\n",
        "\n",
        "print(\"✓ Dataset dividido com sucesso!\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Treino: {stats['train']} imagens\")\n",
        "print(f\"  Validação: {stats['val']} imagens\")\n",
        "print(f\"  Teste: {stats['test']} imagens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA0KO80uMN04"
      },
      "source": [
        "## Parte 4: Anotação do Dataset\n",
        "\n",
        "### ⚠️ IMPORTANTE: Dataset Não Anotado\n",
        "\n",
        "O dataset fornecido **não possui anotações**. Existem três opções:\n",
        "\n",
        "#### Opção 1: Anotação Manual com Roboflow (Recomendado)\n",
        "\n",
        "1. Acesse [Roboflow](https://roboflow.com/)\n",
        "2. Crie um projeto de Object Detection\n",
        "3. Faça upload das imagens\n",
        "4. Anote as imagens (desenhe bounding boxes)\n",
        "5. Defina classes: `ripe` (maduro) e `unripe` (verde)\n",
        "6. Exporte no formato YOLOv8\n",
        "\n",
        "#### Opção 2: Auto-Anotação com Modelo Pré-treinado\n",
        "\n",
        "Usar um modelo YOLO genérico para gerar anotações iniciais (requer revisão manual)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mCgxI5CMN04"
      },
      "outputs": [],
      "source": [
        "# Opção 2: Auto-anotação (EXPERIMENTAL)\n",
        "# Este código gera anotações preliminares que DEVEM ser revisadas\n",
        "\n",
        "def auto_anotar(images_dir, labels_dir, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Gera anotações automáticas usando modelo pré-treinado\n",
        "    ATENÇÃO: Resultados devem ser revisados manualmente!\n",
        "    \"\"\"\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "    images_path = Path(images_dir)\n",
        "    labels_path = Path(labels_dir)\n",
        "    labels_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    images = list(images_path.glob(\"*.png\")) + list(images_path.glob(\"*.jpg\"))\n",
        "\n",
        "    print(f\"Processando {len(images)} imagens...\")\n",
        "\n",
        "    for idx, img_path in enumerate(images, 1):\n",
        "        results = model.predict(source=str(img_path), conf=conf_threshold, verbose=False)\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "        detections = []\n",
        "\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "                x_center = ((x1 + x2) / 2) / w\n",
        "                y_center = ((y1 + y2) / 2) / h\n",
        "                width = (x2 - x1) / w\n",
        "                height = (y2 - y1) / h\n",
        "\n",
        "                class_id = 0  # Temporário\n",
        "                detections.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "        if detections:\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(detections))\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print(f\"Processadas: {idx}/{len(images)}\")\n",
        "\n",
        "    print(\"✓ Auto-anotação concluída!\")\n",
        "    print(\"⚠️  IMPORTANTE: Revise as anotações antes de treinar!\")\n",
        "\n",
        "# Descomentar para executar auto-anotação\n",
        "# auto_anotar('dataset_yolo/images/train', 'dataset_yolo/labels/train')\n",
        "# auto_anotar('dataset_yolo/images/val', 'dataset_yolo/labels/val')\n",
        "# auto_anotar('dataset_yolo/images/test', 'dataset_yolo/labels/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkyB7NuCMN04"
      },
      "source": [
        "#### Opção 3: Usar Dataset Pré-Anotado para Demonstração\n",
        "\n",
        "Para fins didáticos, podemos usar um dataset público já anotado para demonstrar o processo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFFOocgFMN04"
      },
      "outputs": [],
      "source": [
        "# Opção 3: Download de dataset pré-anotado do Roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Substitua pela sua API key do Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR_API_KEY_HERE\")\n",
        "project = rf.workspace(\"moh-s15o3\").project(\"tomato-crop-ccemz\")\n",
        "dataset_demo = project.version(1).download(\"yolov8\")\n",
        "\n",
        "print(f\"Dataset de demonstração baixado em: {dataset_demo.location}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSl7hruMN05"
      },
      "source": [
        "### 4.1. Criar Arquivo data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQT_CWWkMN05"
      },
      "outputs": [],
      "source": [
        "# Criar arquivo de configuração data.yaml\n",
        "yaml_content = \"\"\"# Dataset de Tomates\n",
        "\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "nc: 2\n",
        "names: ['ripe', 'unripe']\n",
        "\"\"\"\n",
        "\n",
        "with open('dataset_yolo/data.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"✓ Arquivo data.yaml criado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CJUZS9NMN05"
      },
      "source": [
        "## Parte 5: Treinamento do Modelo\n",
        "\n",
        "### 5.1. Configuração do Treinamento\n",
        "\n",
        "**Nota:** Para treinar com o dataset fornecido, você precisa primeiro anotar as imagens (Parte 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRs-ZUyfMN05"
      },
      "outputs": [],
      "source": [
        "# Inicializar modelo\n",
        "model = YOLO('yolov8s.pt')  # Modelo small (bom equilíbrio)\n",
        "\n",
        "# Treinar\n",
        "results = model.train(\n",
        "    data='dataset_yolo/data.yaml',  # Ou use dataset_demo.location/data.yaml\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='tomato_detector',\n",
        "    patience=10,\n",
        "    save=True,\n",
        "    device=0,  # GPU\n",
        "    workers=2,\n",
        "    project='runs/detect'\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Treinamento concluído!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrJHE6TMN05"
      },
      "source": [
        "### 5.2. Visualizar Resultados do Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLkfgqnmMN05"
      },
      "outputs": [],
      "source": [
        "# Mostrar gráficos de treinamento\n",
        "from IPython.display import Image as IPImage\n",
        "\n",
        "results_img = 'runs/detect/tomato_detector/results.png'\n",
        "if os.path.exists(results_img):\n",
        "    display(IPImage(filename=results_img, width=900))\n",
        "else:\n",
        "    print(\"Arquivo de resultados não encontrado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoPgbTUIMN05"
      },
      "source": [
        "## Parte 6: Validação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiE3D1JbMN06"
      },
      "outputs": [],
      "source": [
        "# Carregar melhor modelo\n",
        "best_model = YOLO('runs/detect/tomato_detector/weights/best.pt')\n",
        "\n",
        "# Validar\n",
        "metrics = best_model.val()\n",
        "\n",
        "# Exibir métricas\n",
        "print(\"\\n📊 Métricas de Validação:\")\n",
        "print(f\"  mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
        "print(f\"  Precisão: {metrics.box.mp:.4f}\")\n",
        "print(f\"  Recall: {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKSoKHHAMN06"
      },
      "source": [
        "## Parte 7: Inferência em Novas Imagens\n",
        "\n",
        "### 7.1. Testar no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46HHg6suMN06"
      },
      "outputs": [],
      "source": [
        "# Função para detecção e visualização\n",
        "def detectar_e_visualizar(image_path, model, conf=0.3):\n",
        "    results = model.predict(source=image_path, conf=conf, save=False, show=False)\n",
        "    result_img = results[0].plot()\n",
        "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "    return result_img, results[0]\n",
        "\n",
        "# Testar em imagens do conjunto de teste\n",
        "test_images_dir = 'dataset_yolo/images/test'\n",
        "test_images = list(Path(test_images_dir).glob(\"*.png\"))[:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, img_path in enumerate(test_images):\n",
        "    result_img, result = detectar_e_visualizar(str(img_path), best_model)\n",
        "\n",
        "    axes[idx].imshow(result_img)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Detecções: {len(result.boxes)}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBR0llzMN06"
      },
      "source": [
        "### 7.2. Upload e Teste em Imagem Própria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQA47YhHMN06"
      },
      "outputs": [],
      "source": [
        "# Upload de imagem para teste\n",
        "print(\"Faça upload de uma imagem de tomate para testar o modelo:\")\n",
        "uploaded_test = files.upload()\n",
        "\n",
        "# Processar imagem\n",
        "for filename in uploaded_test.keys():\n",
        "    result_img, result = detectar_e_visualizar(filename, best_model, conf=0.25)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(result_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Resultado: {len(result.boxes)} tomates detectados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Detalhes das detecções\n",
        "    print(f\"\\nDetalhes das detecções em {filename}:\")\n",
        "    for i, box in enumerate(result.boxes, 1):\n",
        "        class_id = int(box.cls[0])\n",
        "        confidence = float(box.conf[0])\n",
        "        class_name = result.names[class_id]\n",
        "        print(f\"  {i}. {class_name}: {confidence:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcg1TJIfMN06"
      },
      "source": [
        "## Parte 8: Exportação do Modelo\n",
        "\n",
        "Para usar o modelo em produção ou dispositivos embarcados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njzf9UaNMN06"
      },
      "outputs": [],
      "source": [
        "# Exportar para ONNX (formato universal)\n",
        "best_model.export(format='onnx')\n",
        "\n",
        "print(\"✓ Modelo exportado para ONNX!\")\n",
        "print(\"\\nOutros formatos disponíveis:\")\n",
        "print(\"  - tflite: Para dispositivos móveis (Android/iOS)\")\n",
        "print(\"  - coreml: Para iOS\")\n",
        "print(\"  - engine: Para GPUs NVIDIA (TensorRT)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qx-z29FMN06"
      },
      "source": [
        "## Parte 9: Análise de Resultados\n",
        "\n",
        "### 9.1. Matriz de Confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Umwi992MN06"
      },
      "outputs": [],
      "source": [
        "# Visualizar matriz de confusão\n",
        "confusion_matrix_path = 'runs/detect/tomato_detector/confusion_matrix.png'\n",
        "if os.path.exists(confusion_matrix_path):\n",
        "    display(IPImage(filename=confusion_matrix_path, width=600))\n",
        "else:\n",
        "    print(\"Matriz de confusão não encontrada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qilIS-ntMN06"
      },
      "source": [
        "### 9.2. Exemplos de Predições"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVCmmitiMN07"
      },
      "outputs": [],
      "source": [
        "# Visualizar predições do conjunto de validação\n",
        "val_batch_path = 'runs/detect/tomato_detector/val_batch0_pred.jpg'\n",
        "if os.path.exists(val_batch_path):\n",
        "    display(IPImage(filename=val_batch_path, width=900))\n",
        "else:\n",
        "    print(\"Imagem de predições não encontrada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC1S8R7fMN07"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "### O que aprendemos:\n",
        "\n",
        "1. ✅ Preparar um dataset customizado para YOLOv8\n",
        "2. ✅ Dividir dataset em train/val/test\n",
        "3. ✅ Processo de anotação de imagens\n",
        "4. ✅ Treinar modelo de detecção de objetos\n",
        "5. ✅ Avaliar performance com métricas\n",
        "6. ✅ Fazer inferências em novas imagens\n",
        "7. ✅ Exportar modelo para produção\n",
        "\n",
        "### Próximos Passos:\n",
        "\n",
        "1. **Melhorar o Dataset**: Anotar todas as 895 imagens com precisão\n",
        "2. **Experimentar Hiperparâmetros**: Testar diferentes learning rates, batch sizes\n",
        "3. **Data Augmentation**: Aplicar transformações para melhorar generalização\n",
        "4. **Modelos Maiores**: Testar YOLOv8m ou YOLOv8l para maior precisão\n",
        "5. **Deploy**: Implementar em Raspberry Pi ou Jetson Nano\n",
        "6. **Integração**: Conectar com sistema de robótica agrícola\n",
        "\n",
        "### Recursos Adicionais:\n",
        "\n",
        "- [Documentação Ultralytics](https://docs.ultralytics.com/)\n",
        "- [Roboflow Tutorials](https://blog.roboflow.com/)\n",
        "- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "---\n",
        "\n",
        "**Desenvolvido para Agricultura de Precisão com IA** 🍅🤖"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}