{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prof-eduardo-nunes/unicamp-mineracao_dados/blob/main/Aula_YOLOv8_Dataset_Tomates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FLKz-jSMN00"
      },
      "source": [
        "# Aula Pr√°tica: Detec√ß√£o de Tomates com YOLOv8\n",
        "## Usando Dataset Personalizado (895 Imagens)\n",
        "\n",
        "**Objetivo:** Desenvolver um sistema completo de detec√ß√£o de tomates em lavoura, desde a prepara√ß√£o do dataset at√© o treinamento e infer√™ncia.\n",
        "\n",
        "**Dataset:** 895 imagens de tomates em estufa fornecidas pelo usu√°rio\n",
        "\n",
        "**Aplica√ß√µes Pr√°ticas:**\n",
        "- Colheita automatizada\n",
        "- Monitoramento de matura√ß√£o\n",
        "- Estimativa de produ√ß√£o\n",
        "- Controle de qualidade\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fR6A9lYMN01"
      },
      "source": [
        "## Parte 1: Configura√ß√£o do Ambiente\n",
        "\n",
        "Primeiro, vamos instalar todas as bibliotecas necess√°rias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kMmZYvRMN02",
        "outputId": "ee76b045-5fbc-48f6-ff3a-f24175590dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úì Bibliotecas instaladas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Instala√ß√£o das bibliotecas\n",
        "!pip install \"ultralytics<=8.3.40\" -q\n",
        "!pip install roboflow -q\n",
        "\n",
        "print(\"‚úì Bibliotecas instaladas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tToWyD7-MN02",
        "outputId": "0388d554-218b-471d-b02f-cff800d4c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úì Bibliotecas importadas!\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print(\"‚úì Bibliotecas importadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CapXnVdMN03"
      },
      "source": [
        "## Parte 2: Upload e Prepara√ß√£o do Dataset\n",
        "\n",
        "### 2.1. Upload do Dataset\n",
        "\n",
        "Fa√ßa upload do arquivo `fotostomate.zip` quando solicitado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9XOtsMy4MN03",
        "outputId": "4bc595be-acf3-46fa-bc66-6efd862c2136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, fa√ßa upload do arquivo fotostomate.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d2fe877-f898-4d37-8e77-68cab0183824\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d2fe877-f898-4d37-8e77-68cab0183824\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Upload do arquivo ZIP\n",
        "print(\"Por favor, fa√ßa upload do arquivo fotostomate.zip\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Descompactar\n",
        "!unzip -q fotostomate.zip -d dataset_original\n",
        "print(\"‚úì Dataset descompactado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YSLT0SwMN03"
      },
      "source": [
        "### 2.2. Explora√ß√£o Inicial do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5dadsYAMN03"
      },
      "outputs": [],
      "source": [
        "# Verificar estrutura do dataset\n",
        "!ls -la dataset_original/\n",
        "\n",
        "# Contar imagens\n",
        "image_dir = \"dataset_original/images\"\n",
        "images = list(Path(image_dir).glob(\"*.png\")) + list(Path(image_dir).glob(\"*.jpg\"))\n",
        "print(f\"\\nTotal de imagens: {len(images)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_g54sNMN03"
      },
      "source": [
        "### 2.3. Visualizar Amostras do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-f2Y2ppMN03"
      },
      "outputs": [],
      "source": [
        "# Visualizar 6 imagens aleat√≥rias\n",
        "sample_images = random.sample(images, 6)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, img_path in enumerate(sample_images):\n",
        "    img = Image.open(img_path)\n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"{img_path.name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Observa√ß√µes:\")\n",
        "print(\"- Tomates em diferentes est√°gios de matura√ß√£o\")\n",
        "print(\"- Ambiente de estufa/cultivo protegido\")\n",
        "print(\"- Varia√ß√£o de ilumina√ß√£o e √¢ngulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvDcAjmyMN04"
      },
      "source": [
        "## Parte 3: Divis√£o do Dataset\n",
        "\n",
        "Vamos dividir o dataset em conjuntos de treino (70%), valida√ß√£o (20%) e teste (10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djGYL9cDMN04"
      },
      "outputs": [],
      "source": [
        "def dividir_dataset(source_dir, dest_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Divide o dataset em train/val/test\n",
        "    \"\"\"\n",
        "    # Obter lista de imagens\n",
        "    source_path = Path(source_dir)\n",
        "    images = list(source_path.glob(\"*.png\")) + list(source_path.glob(\"*.jpg\"))\n",
        "\n",
        "    # Embaralhar\n",
        "    random.seed(42)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    # Calcular divis√µes\n",
        "    total = len(images)\n",
        "    train_end = int(total * train_ratio)\n",
        "    val_end = train_end + int(total * val_ratio)\n",
        "\n",
        "    train_images = images[:train_end]\n",
        "    val_images = images[train_end:val_end]\n",
        "    test_images = images[val_end:]\n",
        "\n",
        "    # Criar estrutura de diret√≥rios\n",
        "    dest_path = Path(dest_dir)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        (dest_path / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
        "        (dest_path / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copiar imagens\n",
        "    def copiar(img_list, split):\n",
        "        for img in img_list:\n",
        "            dest = dest_path / 'images' / split / img.name\n",
        "            shutil.copy2(img, dest)\n",
        "\n",
        "    copiar(train_images, 'train')\n",
        "    copiar(val_images, 'val')\n",
        "    copiar(test_images, 'test')\n",
        "\n",
        "    return {\n",
        "        'train': len(train_images),\n",
        "        'val': len(val_images),\n",
        "        'test': len(test_images)\n",
        "    }\n",
        "\n",
        "# Executar divis√£o\n",
        "stats = dividir_dataset('dataset_original/images', 'dataset_yolo')\n",
        "\n",
        "print(\"‚úì Dataset dividido com sucesso!\")\n",
        "print(f\"\\nEstat√≠sticas:\")\n",
        "print(f\"  Treino: {stats['train']} imagens\")\n",
        "print(f\"  Valida√ß√£o: {stats['val']} imagens\")\n",
        "print(f\"  Teste: {stats['test']} imagens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA0KO80uMN04"
      },
      "source": [
        "## Parte 4: Anota√ß√£o do Dataset\n",
        "\n",
        "### ‚ö†Ô∏è IMPORTANTE: Dataset N√£o Anotado\n",
        "\n",
        "O dataset fornecido **n√£o possui anota√ß√µes**. Existem tr√™s op√ß√µes:\n",
        "\n",
        "#### Op√ß√£o 1: Anota√ß√£o Manual com Roboflow (Recomendado)\n",
        "\n",
        "1. Acesse [Roboflow](https://roboflow.com/)\n",
        "2. Crie um projeto de Object Detection\n",
        "3. Fa√ßa upload das imagens\n",
        "4. Anote as imagens (desenhe bounding boxes)\n",
        "5. Defina classes: `ripe` (maduro) e `unripe` (verde)\n",
        "6. Exporte no formato YOLOv8\n",
        "\n",
        "#### Op√ß√£o 2: Auto-Anota√ß√£o com Modelo Pr√©-treinado\n",
        "\n",
        "Usar um modelo YOLO gen√©rico para gerar anota√ß√µes iniciais (requer revis√£o manual)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mCgxI5CMN04"
      },
      "outputs": [],
      "source": [
        "# Op√ß√£o 2: Auto-anota√ß√£o (EXPERIMENTAL)\n",
        "# Este c√≥digo gera anota√ß√µes preliminares que DEVEM ser revisadas\n",
        "\n",
        "def auto_anotar(images_dir, labels_dir, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Gera anota√ß√µes autom√°ticas usando modelo pr√©-treinado\n",
        "    ATEN√á√ÉO: Resultados devem ser revisados manualmente!\n",
        "    \"\"\"\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "    images_path = Path(images_dir)\n",
        "    labels_path = Path(labels_dir)\n",
        "    labels_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    images = list(images_path.glob(\"*.png\")) + list(images_path.glob(\"*.jpg\"))\n",
        "\n",
        "    print(f\"Processando {len(images)} imagens...\")\n",
        "\n",
        "    for idx, img_path in enumerate(images, 1):\n",
        "        results = model.predict(source=str(img_path), conf=conf_threshold, verbose=False)\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "        detections = []\n",
        "\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "                x_center = ((x1 + x2) / 2) / w\n",
        "                y_center = ((y1 + y2) / 2) / h\n",
        "                width = (x2 - x1) / w\n",
        "                height = (y2 - y1) / h\n",
        "\n",
        "                class_id = 0  # Tempor√°rio\n",
        "                detections.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "        if detections:\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(detections))\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print(f\"Processadas: {idx}/{len(images)}\")\n",
        "\n",
        "    print(\"‚úì Auto-anota√ß√£o conclu√≠da!\")\n",
        "    print(\"‚ö†Ô∏è  IMPORTANTE: Revise as anota√ß√µes antes de treinar!\")\n",
        "\n",
        "# Descomentar para executar auto-anota√ß√£o\n",
        "# auto_anotar('dataset_yolo/images/train', 'dataset_yolo/labels/train')\n",
        "# auto_anotar('dataset_yolo/images/val', 'dataset_yolo/labels/val')\n",
        "# auto_anotar('dataset_yolo/images/test', 'dataset_yolo/labels/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkyB7NuCMN04"
      },
      "source": [
        "#### Op√ß√£o 3: Usar Dataset Pr√©-Anotado para Demonstra√ß√£o\n",
        "\n",
        "Para fins did√°ticos, podemos usar um dataset p√∫blico j√° anotado para demonstrar o processo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFFOocgFMN04"
      },
      "outputs": [],
      "source": [
        "# Op√ß√£o 3: Download de dataset pr√©-anotado do Roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Substitua pela sua API key do Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR_API_KEY_HERE\")\n",
        "project = rf.workspace(\"moh-s15o3\").project(\"tomato-crop-ccemz\")\n",
        "dataset_demo = project.version(1).download(\"yolov8\")\n",
        "\n",
        "print(f\"Dataset de demonstra√ß√£o baixado em: {dataset_demo.location}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSl7hruMN05"
      },
      "source": [
        "### 4.1. Criar Arquivo data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQT_CWWkMN05"
      },
      "outputs": [],
      "source": [
        "# Criar arquivo de configura√ß√£o data.yaml\n",
        "yaml_content = \"\"\"# Dataset de Tomates\n",
        "\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "nc: 2\n",
        "names: ['ripe', 'unripe']\n",
        "\"\"\"\n",
        "\n",
        "with open('dataset_yolo/data.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"‚úì Arquivo data.yaml criado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CJUZS9NMN05"
      },
      "source": [
        "## Parte 5: Treinamento do Modelo\n",
        "\n",
        "### 5.1. Configura√ß√£o do Treinamento\n",
        "\n",
        "**Nota:** Para treinar com o dataset fornecido, voc√™ precisa primeiro anotar as imagens (Parte 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRs-ZUyfMN05"
      },
      "outputs": [],
      "source": [
        "# Inicializar modelo\n",
        "model = YOLO('yolov8s.pt')  # Modelo small (bom equil√≠brio)\n",
        "\n",
        "# Treinar\n",
        "results = model.train(\n",
        "    data='dataset_yolo/data.yaml',  # Ou use dataset_demo.location/data.yaml\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='tomato_detector',\n",
        "    patience=10,\n",
        "    save=True,\n",
        "    device=0,  # GPU\n",
        "    workers=2,\n",
        "    project='runs/detect'\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì Treinamento conclu√≠do!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrJHE6TMN05"
      },
      "source": [
        "### 5.2. Visualizar Resultados do Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLkfgqnmMN05"
      },
      "outputs": [],
      "source": [
        "# Mostrar gr√°ficos de treinamento\n",
        "from IPython.display import Image as IPImage\n",
        "\n",
        "results_img = 'runs/detect/tomato_detector/results.png'\n",
        "if os.path.exists(results_img):\n",
        "    display(IPImage(filename=results_img, width=900))\n",
        "else:\n",
        "    print(\"Arquivo de resultados n√£o encontrado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoPgbTUIMN05"
      },
      "source": [
        "## Parte 6: Valida√ß√£o do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiE3D1JbMN06"
      },
      "outputs": [],
      "source": [
        "# Carregar melhor modelo\n",
        "best_model = YOLO('runs/detect/tomato_detector/weights/best.pt')\n",
        "\n",
        "# Validar\n",
        "metrics = best_model.val()\n",
        "\n",
        "# Exibir m√©tricas\n",
        "print(\"\\nüìä M√©tricas de Valida√ß√£o:\")\n",
        "print(f\"  mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
        "print(f\"  Precis√£o: {metrics.box.mp:.4f}\")\n",
        "print(f\"  Recall: {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKSoKHHAMN06"
      },
      "source": [
        "## Parte 7: Infer√™ncia em Novas Imagens\n",
        "\n",
        "### 7.1. Testar no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46HHg6suMN06"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para detec√ß√£o e visualiza√ß√£o\n",
        "def detectar_e_visualizar(image_path, model, conf=0.3):\n",
        "    results = model.predict(source=image_path, conf=conf, save=False, show=False)\n",
        "    result_img = results[0].plot()\n",
        "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "    return result_img, results[0]\n",
        "\n",
        "# Testar em imagens do conjunto de teste\n",
        "test_images_dir = 'dataset_yolo/images/test'\n",
        "test_images = list(Path(test_images_dir).glob(\"*.png\"))[:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, img_path in enumerate(test_images):\n",
        "    result_img, result = detectar_e_visualizar(str(img_path), best_model)\n",
        "\n",
        "    axes[idx].imshow(result_img)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Detec√ß√µes: {len(result.boxes)}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBR0llzMN06"
      },
      "source": [
        "### 7.2. Upload e Teste em Imagem Pr√≥pria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQA47YhHMN06"
      },
      "outputs": [],
      "source": [
        "# Upload de imagem para teste\n",
        "print(\"Fa√ßa upload de uma imagem de tomate para testar o modelo:\")\n",
        "uploaded_test = files.upload()\n",
        "\n",
        "# Processar imagem\n",
        "for filename in uploaded_test.keys():\n",
        "    result_img, result = detectar_e_visualizar(filename, best_model, conf=0.25)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(result_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Resultado: {len(result.boxes)} tomates detectados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Detalhes das detec√ß√µes\n",
        "    print(f\"\\nDetalhes das detec√ß√µes em {filename}:\")\n",
        "    for i, box in enumerate(result.boxes, 1):\n",
        "        class_id = int(box.cls[0])\n",
        "        confidence = float(box.conf[0])\n",
        "        class_name = result.names[class_id]\n",
        "        print(f\"  {i}. {class_name}: {confidence:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcg1TJIfMN06"
      },
      "source": [
        "## Parte 8: Exporta√ß√£o do Modelo\n",
        "\n",
        "Para usar o modelo em produ√ß√£o ou dispositivos embarcados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njzf9UaNMN06"
      },
      "outputs": [],
      "source": [
        "# Exportar para ONNX (formato universal)\n",
        "best_model.export(format='onnx')\n",
        "\n",
        "print(\"‚úì Modelo exportado para ONNX!\")\n",
        "print(\"\\nOutros formatos dispon√≠veis:\")\n",
        "print(\"  - tflite: Para dispositivos m√≥veis (Android/iOS)\")\n",
        "print(\"  - coreml: Para iOS\")\n",
        "print(\"  - engine: Para GPUs NVIDIA (TensorRT)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qx-z29FMN06"
      },
      "source": [
        "## Parte 9: An√°lise de Resultados\n",
        "\n",
        "### 9.1. Matriz de Confus√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Umwi992MN06"
      },
      "outputs": [],
      "source": [
        "# Visualizar matriz de confus√£o\n",
        "confusion_matrix_path = 'runs/detect/tomato_detector/confusion_matrix.png'\n",
        "if os.path.exists(confusion_matrix_path):\n",
        "    display(IPImage(filename=confusion_matrix_path, width=600))\n",
        "else:\n",
        "    print(\"Matriz de confus√£o n√£o encontrada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qilIS-ntMN06"
      },
      "source": [
        "### 9.2. Exemplos de Predi√ß√µes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVCmmitiMN07"
      },
      "outputs": [],
      "source": [
        "# Visualizar predi√ß√µes do conjunto de valida√ß√£o\n",
        "val_batch_path = 'runs/detect/tomato_detector/val_batch0_pred.jpg'\n",
        "if os.path.exists(val_batch_path):\n",
        "    display(IPImage(filename=val_batch_path, width=900))\n",
        "else:\n",
        "    print(\"Imagem de predi√ß√µes n√£o encontrada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC1S8R7fMN07"
      },
      "source": [
        "## Conclus√£o\n",
        "\n",
        "### O que aprendemos:\n",
        "\n",
        "1. ‚úÖ Preparar um dataset customizado para YOLOv8\n",
        "2. ‚úÖ Dividir dataset em train/val/test\n",
        "3. ‚úÖ Processo de anota√ß√£o de imagens\n",
        "4. ‚úÖ Treinar modelo de detec√ß√£o de objetos\n",
        "5. ‚úÖ Avaliar performance com m√©tricas\n",
        "6. ‚úÖ Fazer infer√™ncias em novas imagens\n",
        "7. ‚úÖ Exportar modelo para produ√ß√£o\n",
        "\n",
        "### Pr√≥ximos Passos:\n",
        "\n",
        "1. **Melhorar o Dataset**: Anotar todas as 895 imagens com precis√£o\n",
        "2. **Experimentar Hiperpar√¢metros**: Testar diferentes learning rates, batch sizes\n",
        "3. **Data Augmentation**: Aplicar transforma√ß√µes para melhorar generaliza√ß√£o\n",
        "4. **Modelos Maiores**: Testar YOLOv8m ou YOLOv8l para maior precis√£o\n",
        "5. **Deploy**: Implementar em Raspberry Pi ou Jetson Nano\n",
        "6. **Integra√ß√£o**: Conectar com sistema de rob√≥tica agr√≠cola\n",
        "\n",
        "### Recursos Adicionais:\n",
        "\n",
        "- [Documenta√ß√£o Ultralytics](https://docs.ultralytics.com/)\n",
        "- [Roboflow Tutorials](https://blog.roboflow.com/)\n",
        "- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "---\n",
        "\n",
        "**Desenvolvido para Agricultura de Precis√£o com IA** üçÖü§ñ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}